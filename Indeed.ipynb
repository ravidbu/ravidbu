{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using the way of BeautifulSoup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.indeed.com/jobs?q=data+analytics&start='\n",
    "\n",
    "sort_by = 'date'          # sort by date\n",
    "start_from = '&start='    # start page number\n",
    "\n",
    "pd.set_option('max_colwidth',500)    # to remove column limit (Otherwise, we'll lose some info)\n",
    "df = pd.DataFrame()   # create a new data frame\n",
    "\n",
    "for page in range(2): # page from 1 to 10\n",
    "    page = (page-1) * 10  \n",
    "    url = \"%s%s%s%d\" % (base_url, sort_by, start_from, page) # get full url \n",
    "    page = requests.get(url)\n",
    "    target = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = target.find(id='resultsCol')\n",
    "    BA_jobs = results.find_all('div', class_='title')  \n",
    "    for BA_jobs_link in BA_jobs:\n",
    "        link = BA_jobs_link.find('a')['href']\n",
    "        links = 'http://www.indeed.com/' + link\n",
    "    \n",
    "\n",
    "        website = requests.get(links)\n",
    "        SOUP = BeautifulSoup(website.content, 'html.parser')\n",
    "        job_title_tag = SOUP.find('h3',{'class':'icl-u-xs-mb--xs icl-u-xs-mt--none jobsearch-JobInfoHeader-title'})\n",
    "        job_title = job_title_tag.text[1:-1] if job_title_tag else \"NONE\"\n",
    "        jd_tag = SOUP.find('div',{'class':'jobsearch-jobDescriptionText'})\n",
    "        jd = jd_tag.text[1:-1] if jd_tag else \"NONE\"\n",
    "        \n",
    "        df = df.append({'job_title': job_title,'job_information': jd}, ignore_index=True)\n",
    "\n",
    "        \n",
    "job_data = df.to_csv(\"Indeed_data_analytics.csv\")\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using the way of selenium "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_url = 'https://www.indeed.com/jobs?q=data+analytics&start='\n",
    "\n",
    "# sort_by = 'date'          # sort by date\n",
    "# start_from = '&start='    # start page number\n",
    "\n",
    "# pd.set_option('max_colwidth',500)    # to remove column limit (Otherwise, we'll lose some info)\n",
    "# df = pd.DataFrame()   # create a new data frame\n",
    "# options = webdriver.ChromeOptions()\n",
    "# options.add_argument('headless')\n",
    "    \n",
    "# for page in range(1,51): # page from 1 to 10\n",
    "#     page = (page-1) * 10  \n",
    "#     url = \"%s%s%s%d\" % (base_url, sort_by, start_from, page) # get full url \n",
    "    \n",
    "#     driver = webdriver.Chrome('/Users/guorong/Downloads/chromedriver',options=options)\n",
    "#     driver.get(url)\n",
    "#     time.sleep(2)\n",
    "#     jd_title = driver.find_elements_by_class_name(\"title\")\n",
    "#     for link in jd_title:\n",
    "#         information_link = link.get_attribute('innerHTML')\n",
    "#         target = BeautifulSoup(information_link, 'html.parser')\n",
    "#         LINK = target.find('a')['href']   # we can get all of link with a signle page\n",
    "#         job_title_tage = target.find('a')['title']\n",
    "#         job_title = job_title_tage if job_title_tage else \"NONE\"\n",
    "#         job_url = \"https://www.Indeed.com\" + LINK\n",
    "\n",
    "#         Driver = webdriver.Chrome('/Users/guorong/Downloads/chromedriver',options=options)\n",
    "#         Driver.get(job_url)\n",
    "#         time.sleep(5)\n",
    "\n",
    "#         jd_tag = Driver.find_element_by_id(\"jobDescriptionText\")\n",
    "#         jd = jd_tag.text[1:-1] if jd_tag else \"NONE\"\n",
    "\n",
    "#         df = df.append({'job_title': job_title,'job_information': jd}, ignore_index=True)\n",
    "\n",
    "        \n",
    "# job_data = df.to_csv(\"Indeed_data_analytics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
